{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title pending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "### Attribute Information:\n",
    "This dataset contains information about student study habits, exam performance, and overall knowledge level on the subject of electrical DC machines. The dataset was provided by undergraduate studnets at the Department of Electrical Education of Gazi University. Information on overall knowledge level was collected using an intuitive knowledge classifier \n",
    "\n",
    "### Question: \n",
    "What is a person's overall knowledge level of electrical Direct Current (DC) machines based on their duration of study and number of repeated times studying?\n",
    "\n",
    "### Dataset: \n",
    "The User Knowledge Modeling Data Set was used for this project. This project will develop a method for classifying observations with unknown UNS values. UNS is a type of factor variable which classifies level of student understanding of electrical DC machines. Classification predictions will be made based on the STG and SCG columns, which are double floating point variables that contain observations for degree of study time for relevant materials and the degree of number of repetitions of relevant material during study respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency ‘openxlsx’\n",
      "\n",
      "\n",
      "Warning message in install.packages(\"rio\"):\n",
      "“installation of package ‘openxlsx’ had non-zero exit status”\n",
      "Warning message in install.packages(\"rio\"):\n",
      "“installation of package ‘rio’ had non-zero exit status”\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#readxl doesn't accept URLs, so I'm using the rio library as a workaround.\n",
    "suppressMessages(library(tidyverse))\n",
    "install.packages('rio')\n",
    "library(rio)\n",
    "suppressMessages(library(repr))\n",
    "suppressMessages(library(tidymodels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in import(file = url, sheet = 2, range = \"A1:F259\"): could not find function \"import\"\n",
     "output_type": "error",
     "traceback": [
      "Error in import(file = url, sheet = 2, range = \"A1:F259\"): could not find function \"import\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "#reading and cleaning up the sheets + remerging the training & testing data and reshuffling + transforming UNS into factor data\n",
    "set.seed(3218)\n",
    "\n",
    "url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00257/Data_User_Modeling_Dataset_Hamdi%20Tolga%20KAHRAMAN.xls\"\n",
    "old_knowledge_train <- import(file = url, sheet = 2, range = \"A1:F259\") \n",
    "old_knowledge_train$UNS <- gsub('very_low', 'Very Low', old_knowledge_train$UNS)\n",
    "old_knowledge_test <- import(file = url, sheet = 3, range = \"A1:F146\") \n",
    "old_knowledge_test$UNS <- gsub('very_low', 'Very Low', old_knowledge_test$UNS)\n",
    "knowledge <- rbind(old_knowledge_train, old_knowledge_test) %>%\n",
    "mutate(UNS = as_factor(UNS))\n",
    "knowledge_split <- initial_split(knowledge, prop = 0.65, strata = UNS)\n",
    "knowledge_train <- training(knowledge_split)\n",
    "knowledge_test <- testing(knowledge_split)\n",
    "knowledge_train #not sure how to fix the fact that rows are not consecutively numbered. will take care of this later (unless you feel like doing it)\n",
    "knowledge_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in group_by(knowledge_train, UNS): object 'knowledge_train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in group_by(knowledge_train, UNS): object 'knowledge_train' not found\nTraceback:\n",
      "1. group_by(knowledge_train, UNS) %>% summarize(n = n())",
      "2. eval(lhs, parent, parent)",
      "3. eval(lhs, parent, parent)",
      "4. group_by(knowledge_train, UNS)"
     ]
    }
   ],
   "source": [
    "#finding total number of each class to check for over/underrepresentation\n",
    "class_total <- group_by(knowledge_train, UNS) %>%\n",
    "summarize(n = n())\n",
    "class_total\n",
    "\n",
    "#checking for total missing values in relevant variables\n",
    "is_na <- select(knowledge_train, STG, SCG) %>%\n",
    "summarize(STG_na_total = sum(is.na(STG)), SCG_na_total = sum(is.na(SCG)))\n",
    "is_na\n",
    "\n",
    "#are there any other summary statistics that might be relevant for a classification problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in factor(knowledge_train$UNS, levels = c(\"High\", \"Middle\", \"Low\", : object 'knowledge_train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in factor(knowledge_train$UNS, levels = c(\"High\", \"Middle\", \"Low\", : object 'knowledge_train' not found\nTraceback:\n",
      "1. factor(knowledge_train$UNS, levels = c(\"High\", \"Middle\", \"Low\", \n .     \"Very Low\"))"
     ]
    }
   ],
   "source": [
    "#visualization with relevant predictor variables\n",
    "#the data seems to have been standardized in some way, but I'm not certain exactly what they did? I don't see any information about this\n",
    "#on the sheets. if you figure out what it is please lmk\n",
    "options(repr.plot.width = 10, repr.plot.height = 8) \n",
    "knowledge_train$UNS <- (factor(knowledge_train$UNS, levels = c('High', 'Middle', 'Low', 'Very Low'))) #the way i rearranged this legend is kind of goofy. feel free to clean it up\n",
    "knowledge_plot <- ggplot(knowledge_train, aes(x = STG, y = SCG, color = knowledge_train$UNS)) +\n",
    "geom_point(alpha = 0.5) + #there aren't too many overlapping points, but we might want to include an alpha value?\n",
    "labs(x = 'Degree of Study Time for Relevant Material (Standardized?)', y = 'Degree of Number of Repetitions of Relevant Material During Study (standardized?)', color = 'Level of Knowledge of Material') +\n",
    "ggtitle(\"Graph of Study Time vs. Study Repetitions for Material Related to Electrical DC Machines\") +\n",
    "theme(text = element_text(size = 15)) +\n",
    "scale_color_brewer(palette = 'Set2') #colourblind friendly. feel free to choose an alternate option, though.\n",
    "knowledge_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "1. We will use Rio, Repr Tidyverse, and Tidymodels libraries.\n",
    "2. Import file into the software. Clean and wrangle data. <br>\n",
    "    a. Legend is made uniform using Gsub function. <br>\n",
    "    b. Dataset is already split into training and testing sets. In order to display our knowledge, we bind the datasets and split again.\n",
    "3. Do summary statistics on training/testing data where applicable.\n",
    "4. Visualize training data.\n",
    "5. Split training data into C groups. Perform cross-validation to determine best fit for K.\n",
    "6. Produce a visualization of K accuracy. Use the K-value with the most accurate prediction accuracy.\n",
    "7. Prepare classification model (recipe, model, workflow, fit).\n",
    "8. Predict on testing data.\n",
    "9. Collect metrics and do a confusion matrix on the prediction to assess accuracy.\n",
    "10. (If need be) try again with alternate K values to increase accuracy. \n",
    "11. Produce a visualization of results.\n",
    "12. Create accuracy matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Outcomes and Significance\n",
    "1. What do you expect to find? <br>\n",
    "    a. Most optimal K-value\n",
    "    b. Variable that impacts prediction more\n",
    "2. What impact could such findings have? <br>\n",
    "    a. K-value impacts our model and specifications\n",
    "    b. Knowing which of these variables affects knowledge level more would provide insight into more effective study strategies\n",
    "3. What future questions could this lead to? <br>\n",
    "    a. How do we test for the variable that weighs more?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
